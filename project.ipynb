{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-04T11:55:20.620805300Z",
     "start_time": "2023-12-04T11:55:20.571776400Z"
    }
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from networkx.algorithms import bipartite\n",
    "from collections import Counter\n",
    "from networkx.linalg.graphmatrix import adjacency_matrix\n",
    "\n",
    "from statistics import mean\n",
    "\n",
    "# Loading data pathes and I/O functions from script\n",
    "from scripts.io import load_movie_titles, load_raw_bipartite, save_projection, load_projection, save_edgelist, projection_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading bipartite graph and movie titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-04T11:55:20.733300900Z",
     "start_time": "2023-12-04T11:55:20.578777700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph loaded.\n"
     ]
    }
   ],
   "source": [
    "title_dict, node_dict = load_movie_titles(\"movie-titles.txt\")\n",
    "G = load_raw_bipartite(\"full_bipartite.p\")\n",
    "\n",
    "# Split the graph into 2 sets: user and movie nodes\n",
    "user_nodes, movie_nodes = nx.algorithms.bipartite.basic.sets(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple weights projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-04T11:55:22.116821600Z",
     "start_time": "2023-12-04T11:55:20.697302700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Projection loaded.\n",
      "Projection loaded.\n"
     ]
    }
   ],
   "source": [
    "# Projecting on users\n",
    "simple_weights_users_path = \"simple_weights_users.p\"\n",
    "\n",
    "if os.path.exists(projection_path+simple_weights_users_path):\n",
    "    simple_weights_users = load_projection(simple_weights_users_path)\n",
    "else:\n",
    "    simple_weights_users = bipartite.weighted_projected_graph(G, user_nodes, ratio=True)\n",
    "    save_projection(simple_weights_users, simple_weights_users_path)\n",
    "\n",
    "# Projecting on movies\n",
    "simple_weights_movies_path = \"simple_weights_movies.p\"\n",
    "\n",
    "if os.path.exists(projection_path+simple_weights_movies_path):\n",
    "    simple_weights_movies = load_projection(simple_weights_movies_path)\n",
    "else:\n",
    "    simple_weights_movies = bipartite.weighted_projected_graph(G, movie_nodes, ratio=True)\n",
    "    save_projection(simple_weights_movies, simple_weights_movies_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Research Question\n",
    "How can we recommend movies, given movies you like?\n",
    "\n",
    "#### Idea for an algorithm where projections take ratings into account in some way:\n",
    "1. Get input of movies you like, M, which have ratings by users U\n",
    "2. Project U and M onto U to get U1\n",
    "3. Project U1, and all movies they rated, onto the movies to get M1\n",
    "4. Recommend, from M1, the highest weight neighbor(s) of M.\n",
    "\n",
    "#### Other ideas:\n",
    "* Sample users who liked the movie(s), project onto their rated movies, recommend highest weight neighbor of liked movies.  \n",
    "* Construct similar movies to the ones you like, use this to find users like you, and iterate to converge on movies you will like.  \n",
    "\n",
    "Potential problem: if our sample of users is too large, we are likely to just recommend the most rated movies, not specific movies you would like. To test this, we could plot correlation between movie degree and likelihood to recommend.  \n",
    "\n",
    "Does backboning M1 improve recommendations?  \n",
    "\n",
    "How can we take movie genre into account for recommendation?  \n",
    "\n",
    "Are our movie recommendations associated with genre? i.e. does M1 have high genre\n",
    "homophily?  \n",
    "\n",
    "Are our recommendations largely popular or niche movies and why?  \n",
    "\n",
    "For evaluation, can we use cross validation by comparing usersâ€™ ratings to how likely we are to recommend each rated movie, based on a sample of movies they like?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our Projection Methods\n",
    "\n",
    "## Rating Allocation\n",
    "Projection algorithm inspired by resource allocation, where directed edge weight from movie1 to movie2 is computed by summing over all users who rated both movies, multiplying their rating of movie1, normalized by all movie1's ratings, with their rating of movie2, normalized by the users total ratings.\n",
    "\n",
    "$$RA_{m1,m2} = \\sum_{u \\in N_{m1} \\cap N_{m2}} \\frac{w_{m1,u}}{\\sum{w_{m1}}}\\frac{w_{u,m2}}{\\sum{w_{u}}}$$ \n",
    "\n",
    "this is computed for all $m1,m2$ pairs of movies, excluding self-loops, to produce a directed movie graph.\n",
    "\n",
    "An issue with this approach: Ratings below average (e.g. 1) increase weight compared to no rating, which seems intuitively wrong.\n",
    "Could this be solved by assuming no rating = average rating?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2023-12-04T11:55:22.128100700Z",
     "start_time": "2023-12-04T11:55:22.119820500Z"
    }
   },
   "outputs": [],
   "source": [
    "def find_common_neighbors(u, v):\n",
    "    N_u = G.neighbors(u)\n",
    "    N_v = G.neighbors(v)\n",
    "    return set(N_u) & set(N_v)\n",
    "\n",
    "def rating_allocation_edge_weight(G, u, v, degree_u):\n",
    "    N_u_v = find_common_neighbors(u,v)\n",
    "    weight_u_v = 0\n",
    "    for n in N_u_v:\n",
    "        w_u_n = G.get_edge_data(u,n)['weight']\n",
    "        w_n_v = G.get_edge_data(n,v)['weight']\n",
    "        if w_u_n <= 3 or w_n_v <= 3:\n",
    "            weight_invariant = -1\n",
    "        else:\n",
    "            weight_invariant = 1\n",
    "        weight_u_v += weight_invariant * (w_u_n / degree_u * w_n_v / G.degree(n))\n",
    "    return weight_u_v\n",
    "\n",
    "def rating_allocation_projection(G, movie_nodes):\n",
    "    rating_allocation_graph = nx.DiGraph()\n",
    "    for u in movie_nodes:\n",
    "        degree_u = G.degree(u)\n",
    "        for v in movie_nodes:\n",
    "\n",
    "            # Prevent self-loops\n",
    "            if v == u:\n",
    "                continue\n",
    "\n",
    "            edge_weight = rating_allocation_edge_weight(G, u, v, degree_u)\n",
    "            rating_allocation_graph.add_edge(u, v, weight=edge_weight)\n",
    "            \n",
    "    return rating_allocation_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-04T11:55:24.043341500Z",
     "start_time": "2023-12-04T11:55:22.133134700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Projection loaded.\n"
     ]
    }
   ],
   "source": [
    "# Saving/loading rating allocation projection on movies\n",
    "rating_allocation_movies_path = \"rating_allocation_movies.p\"\n",
    "\n",
    "if os.path.exists(projection_path+rating_allocation_movies_path):\n",
    "    rating_allocation_movies = load_projection(rating_allocation_movies_path)\n",
    "else:\n",
    "    rating_allocation_movies = rating_allocation_projection(G, movie_nodes)\n",
    "    save_projection(rating_allocation_movies, rating_allocation_movies_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving edge lists for visualization with Gephi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-04T11:55:24.049343Z",
     "start_time": "2023-12-04T11:55:24.046341400Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Getting 50 highest degree movies\n",
    "\n",
    "# TODO: Pass these to save_edgelist\n",
    "# save_edgelist(50, rating_allocation_movies, \"rating_allocation_movies_edges\", title_dict, overwrite=True)\n",
    "# save_edgelist(50, simple_weights_movies, \"simple_weights_movies_edges\", title_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-04T11:55:24.057909400Z",
     "start_time": "2023-12-04T11:55:24.052341400Z"
    }
   },
   "outputs": [],
   "source": [
    "# liked_movie_list = ['Die Hard (1988)', 'Star Wars (1977)']\n",
    "# graph = rating_allocation_movies\n",
    "# liked_movie_node_list = [node_dict[liked_movie_title] for liked_movie_title in liked_movie_list]\n",
    "# neighbors_weights = dict()\n",
    "# for liked_movie_node in liked_movie_node_list:  # For each of the liked movies\n",
    "#     for node, neighbor, attr_dict in graph.edges(liked_movie_node, data=True):  # For each of its edges\n",
    "        \n",
    "#         # Avoid edges to liked movies\n",
    "#         if neighbor in liked_movie_node_list:\n",
    "#             continue\n",
    "        \n",
    "#         # Append weight to neighbor to dict of all weights\n",
    "#         neighbors_weights.setdefault(neighbor, []).append(attr_dict['weight'])  \n",
    "\n",
    "# # Average over all weights for each movie\n",
    "# avg_neighbors_weights = [(node, mean(weights)) for node, weights in neighbors_weights.items()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-04T11:55:24.099039400Z",
     "start_time": "2023-12-04T11:55:24.060909800Z"
    }
   },
   "outputs": [],
   "source": [
    "# # To recommend, find highest weight movie from movie you like\n",
    "\n",
    "# def k_highest_weight_neighbors(k, liked_movie_title, graph):\n",
    "    \n",
    "#     liked_movie_node = node_dict[liked_movie_title]\n",
    "#     edges = list(graph.edges(liked_movie_node, data=True))\n",
    "\n",
    "#     neighbors_weights = [(neighbor, weight['weight']) for node, neighbor, weight in edges]\n",
    "#     neighbors_weights = sorted(neighbors_weights, reverse=True, key=lambda x: x[1])\n",
    "\n",
    "#     neighbors_weights_dict = dict((node, find_neighbor_weights(edges[node])) for node in edges.keys())\n",
    "\n",
    "#     n_neighbors = [(title_dict[neighbor],weight) for neighbor, weight in neighbors_weights][:k]\n",
    "\n",
    "#     print(f\"{k} highest weight neighbors of '{liked_movie_title}':\")\n",
    "#     return n_neighbors\n",
    "\n",
    "# k_highest_weight_neighbors(10, 'Die Hard (1988)', rating_allocation_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-04T11:55:24.099039400Z",
     "start_time": "2023-12-04T11:55:24.070047100Z"
    }
   },
   "outputs": [],
   "source": [
    "#rating_allocation_movies.edges(data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-04T11:55:24.123412800Z",
     "start_time": "2023-12-04T11:55:24.075039500Z"
    }
   },
   "outputs": [],
   "source": [
    "liked_movie_list = [\"Godfather, The (1972)\"]\n",
    "# print(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-04T11:55:24.162966Z",
     "start_time": "2023-12-04T11:55:24.133411200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Star Wars (1977)', 0.1297339030994218), ('Fargo (1996)', 0.10508866438488587), ('Return of the Jedi (1983)', 0.06020334698017408), ('Boot, Das (1981)', 0.060159506308073867), ('Silence of the Lambs, The (1991)', 0.05639760334732199), ('Toy Story (1995)', 0.054284909760981166), ('Raiders of the Lost Ark (1981)', 0.05358820339586955), ('Shawshank Redemption, The (1994)', 0.0505984353433188), ('Godfather: Part II, The (1974)', 0.049942158867375686), ('English Patient, The (1996)', 0.04812258467726199)]\n"
     ]
    }
   ],
   "source": [
    "def get_edges(liked_movie_list,d_graph):\n",
    "    liked_movie_node_list = [node_dict[liked_movie_title] for liked_movie_title in liked_movie_list]\n",
    "    edges = dict((liked_movie_node, list(d_graph.edges(liked_movie_node, data=True))) for liked_movie_node in liked_movie_node_list)\n",
    "    return edges\n",
    "\n",
    "edges = get_edges(liked_movie_list, rating_allocation_movies)\n",
    "\n",
    "def get_average_weight_per_movie(edges):\n",
    "    node_weights = dict()\n",
    "    for node, edges_list in edges.items():\n",
    "        for edge in edges_list:\n",
    "            if edge[1] in edges.keys():\n",
    "                continue\n",
    "            if edge[1] in node_weights:\n",
    "                node_weights[edge[1]].append(edge[2]['weight'])\n",
    "            else:\n",
    "                node_weights[edge[1]] = [edge[2]['weight']]\n",
    "        average_weights = [(node,mean(weights)) for node, weights in node_weights.items()]\n",
    "    return average_weights\n",
    "\n",
    "def sort_average_weight(average_weight_edges):\n",
    "    return sorted(average_weight_edges, reverse=True, key=lambda x: x[1])\n",
    "\n",
    "def k_recommend_from_list(k, rating_allocation_movies, liked_movie_list):\n",
    "    edges = get_edges(liked_movie_list, rating_allocation_movies)\n",
    "    sorted_average_weights = sort_average_weight(get_average_weight_per_movie(edges))\n",
    "    n_neighbors = [(title_dict[neighbor],weight) for neighbor, weight in sorted_average_weights][:k]\n",
    "    return n_neighbors\n",
    "print(k_recommend_from_list(10,rating_allocation_movies, liked_movie_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-04T11:55:24.168964500Z",
     "start_time": "2023-12-04T11:55:24.163963100Z"
    }
   },
   "outputs": [],
   "source": [
    "#k = 10\n",
    "#n_neighbors = [(title_dict[neighbor],weight) for neighbor, weight in sorted_average_weights][:k]\n",
    "#print(n_neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-04T11:55:24.178731500Z",
     "start_time": "2023-12-04T11:55:24.171286900Z"
    }
   },
   "outputs": [],
   "source": [
    "# For multiple likes movies, find highest average weight movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-04T11:55:24.182728400Z",
     "start_time": "2023-12-04T11:55:24.179730Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
