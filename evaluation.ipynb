{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "205ba06f-0e54-48da-b86a-c782fce43a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from networkx.algorithms import bipartite\n",
    "import numpy as np\n",
    "import random\n",
    "from scipy.stats import spearmanr, permutation_test\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "# Loading data pathes and I/O functions from script\n",
    "from scripts.io import load_movie_titles, load_raw_bipartite, save_projection, load_projection, save_edgelist, projection_path\n",
    "\n",
    "# Loading reccomendation function\n",
    "from scripts.recommend import evaluation_recommendation, sort_average_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e622e0f2-fdaf-4bd2-997e-70181ff118c4",
   "metadata": {},
   "source": [
    "## Loading dicts and graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c14d5c3-75cf-4c7f-9c30-10bb549e2cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie titles loaded.\n",
      "Graph loaded.\n",
      "Projection loaded.\n",
      "Projection loaded.\n"
     ]
    }
   ],
   "source": [
    "title_dict, node_dict = load_movie_titles(\"movie-titles.txt\")\n",
    "\n",
    "G = load_raw_bipartite(\"full_bipartite.p\")\n",
    "\n",
    "simple_weights_movies = load_projection(\"simple_weights_movies.p\")\n",
    "rating_allocation_movies = load_projection(\"rating_allocation_movies.p\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c72a3b-4cbd-4f2f-b8f6-9a210a59f815",
   "metadata": {},
   "source": [
    "# Evaluation algorithm\n",
    "    Cross-validation of movie recommendations from graph with empirical ratings by users.\n",
    "\n",
    "    For each user:\n",
    "        1. Sample k liked (highest rated) movies, M, from list of rated movies, L ((movie_node, rating) list).\n",
    "        2. Get movie recommendations, R ((movie_node, average_weight) list), based on M, for each movie in L.\n",
    "        3. Sort R and L by average_weight/rating, then discard movie_node from both.\n",
    "        5. Compute and store spearman rank correlation between R and L. If correlation has p>0.05, it's assumed to be 0.\n",
    "        \n",
    "    Output average rank correlation for all users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee88cf79-342e-4b4f-bdd6-88289f40e860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Correlations: [0.0001, 0.001, 0.01, 0.02, 0.03, 0.04, 0.05, 0.1]\n",
      "Corrected Correlations: [0.0008     0.004      0.02666667 0.04       0.048      0.05333333\n",
      " 0.05714286 0.1       ]\n"
     ]
    }
   ],
   "source": [
    "# Testing p-value correction\n",
    "correlations = [0.0001, 0.001, 0.01, 0.02, 0.03, 0.04, 0.05, 0.1]\n",
    "_, corrected_correlations, _, _ = multipletests(correlations, method='fdr_bh')\n",
    "\n",
    "# Print the original and corrected correlations\n",
    "print(\"Original Correlations:\", correlations)\n",
    "print(\"Corrected Correlations:\", corrected_correlations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9592ecee-be90-4428-93b6-fe66a6511f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(movie_graph, k=3, G=G, seed=None):\n",
    "    \"\"\"\n",
    "    Cross-validation of movie recommendations from graph with empirical ratings of users.\n",
    "    \n",
    "    parameters:\n",
    "        movie_graph (nx.Graph or nx.DiGraph) graph from which to recommend movies by highest weight neighbors\n",
    "        k (int) number of liked movies to sample from each user for recommendation\n",
    "        G (nx.Graph) bipartite graph of users and movies\n",
    "        seed (int) enables reproducibility of evaluation randomness\n",
    "    prints:\n",
    "        average correlation\n",
    "        standard deviation\n",
    "        percentage of correlations which were insignificant (<0.05), after correction\n",
    "    \"\"\"\n",
    "\n",
    "    # Validating and setting parameters\n",
    "    if type(movie_graph) not in [nx.Graph, nx.DiGraph] or type(G) not in [nx.Graph, nx.DiGraph] or type(k) != int or type(seed) != int:\n",
    "        raise TypeError(\"Called evaluate() with argument of wrong type.\")\n",
    "    if seed:\n",
    "        random.seed(seed)\n",
    "\n",
    "    # Getting users and movies from bipartite graph (this could be moved outside evaluate() to save time)\n",
    "    user_nodes, movie_nodes = nx.algorithms.bipartite.basic.sets(G)\n",
    "\n",
    "    # Correlation (and p-value) between each user's ratings and recommendations\n",
    "    correlations = []  \n",
    "    p_values = []\n",
    "\n",
    "    ##### For each user #####\n",
    "    for user_node in user_nodes:\n",
    "\n",
    "        ##### 1. Sample k liked (highest rated) movies #####\n",
    "        \n",
    "        # All rated movies and ratings of user\n",
    "        movie_rating_tuples = [(movie_node,attr_dict['weight']) for movie_node, attr_dict in dict(G[user_node]).items()]  \n",
    "\n",
    "        # Movies are shuffled, to randomize order of movies with the same rating\n",
    "        random.shuffle(movie_rating_tuples)  \n",
    "        \n",
    "        # Movies are sorted by rating\n",
    "        movie_rating_tuples = sorted(movie_rating_tuples, reverse=True, key=lambda x:x[1])\n",
    "        rated_movies = [movie_node for movie_node, weight in movie_rating_tuples]\n",
    "        \n",
    "        # k highest rated movies are sampled and removed from rated_movies\n",
    "        k_most_liked_movie_nodes = rated_movies[:k]\n",
    "        liked_movie_nodes = rated_movies[k:]\n",
    "        \n",
    "        ##### 2. Get movie recommendations #####\n",
    "        \n",
    "        recommended_movie_nodes = evaluation_recommendation(movie_graph, k_most_liked_movie_nodes, liked_movie_nodes)\n",
    "\n",
    "        assert len(recommended_movie_nodes) <= len(liked_movie_nodes)\n",
    "\n",
    "        # Extending recommendations with missing nodes (this is necessary in simple weights, since not all movies are connected)\n",
    "        # They are randomly shuffled and added to the end of recommended movies\n",
    "        if len(recommended_movie_nodes) < len(liked_movie_nodes):\n",
    "            missing_nodes = [node for node in liked_movie_nodes if node not in recommended_movie_nodes]\n",
    "            random.shuffle(missing_nodes)\n",
    "            recommended_movie_nodes.extend(missing_nodes)\n",
    "        \n",
    "        assert len(liked_movie_nodes) == len(recommended_movie_nodes), f\"Lengths don't match: {len(liked_movie_nodes)} != {len(recommended_movie_nodes)}.\"\n",
    "        assert set(liked_movie_nodes) == set(recommended_movie_nodes), \"Node sets don't match.\"\n",
    "        \n",
    "        ##### 4. Compute and store spearman rank correlation (and p value) between R and L.\n",
    "\n",
    "        # Null hypothesis is that the correlation is not positive, alternative hypothesis is that correlation is positive.\n",
    "        # Because some people have rated few movies, we use permutation test like in 'Examples' at https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.spearmanr.html\n",
    "        \n",
    "        res = permutation_test((liked_movie_nodes, recommended_movie_nodes), statistic, alternative='greater', permutation_type='pairings')\n",
    "        correlations.append(res.statistic)\n",
    "        p_values.append(res.pvalue)\n",
    "    \n",
    "    _, corrected_p_values, _, _ = multipletests(p_values, method='fdr_bh')  # Using Benjamini/Hochberg FDR correction (because we test many pre-detemined hypotheses) \n",
    "\n",
    "    # if p>0.05, correlation is set to 0\n",
    "    for i, p_value in enumerate(corrected_p_values):\n",
    "        if p_value>0.05:\n",
    "            correlations[i] = 0\n",
    "\n",
    "    # Computing and printing result\n",
    "    mean_correlation = np.mean(correlations)\n",
    "    std_correlation = np.std(correlations)\n",
    "    non_significant_proportion = np.mean(np.array(correlations)==0)\n",
    "    print(f\"Average correlation ± std: {mean_correlation}±{std_correlation}, non-significant: {non_significant_proportion}\")\n",
    " \n",
    "def statistic(x, y):  # explore all possible pairings by permuting `x`\n",
    "    dof = len(x)-2  # Degrees of are number of observations minus number of variables\n",
    "    rs = spearmanr(x, y).statistic  # ignore pvalue\n",
    "\n",
    "    # Prevent divide-by-zero error\n",
    "    if (rs+1.0)*(1.0-rs)==0.0:\n",
    "        return -1\n",
    "\n",
    "    transformed = rs * np.sqrt(dof / ((rs+1.0)*(1.0-rs)))\n",
    "    return transformed\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing parts of the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "640f1c55-757f-464c-b8f7-10578f3fffcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate(simple_weights_movies, k=3, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liked: ['Fargo (1996)']\n",
      "Recommended: ['Toy Story (1995)', 'GoldenEye (1995)', 'Four Rooms (1995)']\n",
      "[1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "liked_movies = [100]\n",
    "rated_movies = [3,2,1]\n",
    "recommended = evaluation_recommendation(simple_weights_movies, liked_movies, rated_movies)\n",
    "print(f\"Liked: {[title_dict[node] for node in liked_movies]}\")\n",
    "print(f\"Recommended: {[title_dict[node] for node in recommended]}\")\n",
    "print(recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b644dd2f-fd12-4363-84ba-34a92a4b2141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation: 0.200 ± 0.183, 33% non-significant.\n"
     ]
    }
   ],
   "source": [
    "correlations = [0, 0.1, 0.5, 0.3, 0.3, 0.0]\n",
    "\n",
    "mean_correlation = np.mean(correlations)\n",
    "std_correlation = np.std(correlations)\n",
    "non_significant_proportion = np.mean(np.array(correlations)==0)\n",
    "print(f\"Correlation: {mean_correlation:.3f} ± {std_correlation:.3f}, {non_significant_proportion:.0%} non-significant.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1 0.831\n"
     ]
    }
   ],
   "source": [
    "liked_movie_nodes = [1,2,3,4,5,6,7,8,9]\n",
    "recommended_movie_nodes = [9,8,7,6,5,4,3,2,1]\n",
    "\n",
    "res = permutation_test((liked_movie_nodes, recommended_movie_nodes), statistic, alternative='greater', permutation_type='pairings')\n",
    "print(res.statistic,res.pvalue)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
