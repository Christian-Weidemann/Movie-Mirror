{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "205ba06f-0e54-48da-b86a-c782fce43a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from networkx.algorithms import bipartite\n",
    "import numpy as np\n",
    "import random\n",
    "from scipy.stats import spearmanr\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "# Loading data pathes and I/O functions from script\n",
    "from scripts.io import load_movie_titles, load_raw_bipartite, save_projection, load_projection, save_edgelist, projection_path\n",
    "\n",
    "# Loading reccomendation function\n",
    "from scripts.recommend import evaluation_recommendation, sort_average_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e622e0f2-fdaf-4bd2-997e-70181ff118c4",
   "metadata": {},
   "source": [
    "## Loading dicts and graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c14d5c3-75cf-4c7f-9c30-10bb549e2cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph loaded.\n",
      "Projection loaded.\n",
      "Projection loaded.\n"
     ]
    }
   ],
   "source": [
    "G = load_raw_bipartite(\"full_bipartite.p\")\n",
    "\n",
    "simple_weights_movies = load_projection(\"simple_weights_movies.p\")\n",
    "rating_allocation_movies = load_projection(\"rating_allocation_movies.p\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c72a3b-4cbd-4f2f-b8f6-9a210a59f815",
   "metadata": {},
   "source": [
    "# Evaluation algorithm\n",
    "    Cross-validation of movie recommendations from graph with empirical ratings by users.\n",
    "\n",
    "    For each user:\n",
    "        1. Sample k liked (highest rated) movies, M, from list of rated movies, L ((movie_node, rating) list).\n",
    "        2. Get movie recommendations, R ((movie_node, average_weight) list), based on M, for each movie in L.\n",
    "        3. Sort R and L by average_weight/rating, then discard movie_node from both.\n",
    "        5. Compute and store spearman rank correlation between R and L. If correlation has p>0.05, it's assumed to be 0.\n",
    "        \n",
    "    Output average rank correlation for all users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ee88cf79-342e-4b4f-bdd6-88289f40e860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Correlations: [0.0001, 0.001, 0.01, 0.02, 0.03, 0.04, 0.05, 0.1]\n",
      "Corrected Correlations: [0.0008     0.004      0.02666667 0.04       0.048      0.05333333\n",
      " 0.05714286 0.1       ]\n"
     ]
    }
   ],
   "source": [
    "# Testing p-value correction\n",
    "correlations = [0.0001, 0.001, 0.01, 0.02, 0.03, 0.04, 0.05, 0.1]\n",
    "_, corrected_correlations, _, _ = multipletests(correlations, method='fdr_bh')\n",
    "\n",
    "# Print the original and corrected correlations\n",
    "print(\"Original Correlations:\", correlations)\n",
    "print(\"Corrected Correlations:\", corrected_correlations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9592ecee-be90-4428-93b6-fe66a6511f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(movie_graph, k=3, G=G, seed=None, default_rating='zero'):\n",
    "    \"\"\"\n",
    "    Cross-validation of movie recommendations from graph with empirical ratings of users.\n",
    "    \n",
    "    parameters:\n",
    "        movie_graph (nx.Graph or nx.DiGraph) graph from which to recommend movies by highest weight neighbors\n",
    "        k (int) number of liked movies to sample from each user for recommendation\n",
    "        G (nx.Graph) bipartite graph of users and movies\n",
    "        seed (int) enables reproducibility of evaluation randomness\n",
    "        default_rating (str) determines for each user the assumed rating of non-rated movies. Can be 'zero' or 'mean' (user's average rating).\n",
    "    returns:\n",
    "        average_correlation \n",
    "    \"\"\"\n",
    "\n",
    "    # Validating and setting parameters\n",
    "    if type(movie_graph) not in [nx.Graph, nx.DiGraph] or type(G) not in [nx.Graph, nx.DiGraph] or type(k) != int or type(seed) != int:\n",
    "        raise TypeError(\"Called evaluate() with argument of wrong type.\")\n",
    "    if default_rating not in ['zero', 'mean']:\n",
    "        raise ValueError(\"default_rating argument must be 'zero' or 'mean'. Default is 'zero'.\")\n",
    "    if default_rating == 'zero':\n",
    "            default_rating = 0\n",
    "    if seed:\n",
    "        random.seed(seed)\n",
    "\n",
    "    # Getting users and movies from bipartite graph (this could be moved outside evaluate() to save time)\n",
    "    user_nodes, movie_nodes = nx.algorithms.bipartite.basic.sets(G)\n",
    "\n",
    "    # Correlation (and p-value) between each user's ratings and recommendations\n",
    "    correlations = []  \n",
    "    p_values = []\n",
    "    \n",
    "    # Proportion of correlations which have p>0.05\n",
    "    not_significant_correlations = 0\n",
    "\n",
    "    ##### For each user #####\n",
    "    for user_node in user_nodes:\n",
    "\n",
    "        ##### 1. Sample k liked (highest rated) movies #####\n",
    "        \n",
    "        # All rated movies and ratings of user\n",
    "        movie_rating_tuples = [(movie_node,attr_dict['weight']) for movie_node, attr_dict in dict(G[user_node]).items()]  \n",
    "\n",
    "        # Determining default rating\n",
    "\n",
    "        if default_rating == 'mean':\n",
    "            ratings = [weight for movie_node, weight in movie_rating_tuples]\n",
    "            default_rating = np.mean(ratings)\n",
    "\n",
    "        # Adding not rated movies with rating default_rating\n",
    "        not_rated_movies = [movie for movie in movie_nodes if movie not in rated_movies]\n",
    "\n",
    "        \n",
    "        # Movies are shuffled, to randomize order of movies with the same rating\n",
    "        random.shuffle(movie_rating_tuples)  \n",
    "        \n",
    "        # Movies are sorted by rating\n",
    "        movie_rating_tuples = sorted(movie_rating_tuples, reverse=True, key=lambda x:x[1])\n",
    "        rated_movies = [movie_node for movie_node, weight in movie_rating_tuples]\n",
    "\n",
    "        \n",
    "            \n",
    "        \n",
    "        # k highest rated movies are sampled\n",
    "        k_most_liked_movie_nodes = rated_movies[:k]\n",
    "        \n",
    "        # Removing sampled nodes from liked movies\n",
    "        rated_movies = rated_movies[k:]\n",
    "        \n",
    "        \n",
    "        ##### 2. Get movie recommendations #####\n",
    "        \n",
    "        recommended_movie_nodes = evaluation_recommendation(movie_graph, k_most_liked_movie_nodes)\n",
    "\n",
    "        # Extending recommendations with missing nodes (this is necessary in simple weights, since not all movies are connected)\n",
    "        if len(recommended_movie_nodes) < len(movie_graph.nodes):\n",
    "            missing_nodes = [node for node in movie_graph.nodes if node not in recommended_movie_nodes]\n",
    "            random.shuffle(missing_nodes)  # randomizing order of non-recommended nodes\n",
    "            recommended_movie_nodes.extend(missing_nodes)\n",
    "        \n",
    "        \n",
    "        \n",
    "        assert len(liked_movie_nodes) == len(recommended_movie_nodes), f\"Lengths don't match: {len(liked_movie_nodes)} != {len(recommended_movie_nodes)}.\"\n",
    "        assert set(liked_movie_nodes) == set(recommended_movie_nodes), \"Node sets don't match.\"\n",
    "\n",
    "        \n",
    "        # ##### 3. Sort R and L by node #####\n",
    "        # liked_movie_nodes = sorted(liked_movie_nodes, key=lambda x:x[0])\n",
    "        # recommended_movie_nodes = sorted(recommended_movie_nodes, key=lambda x:x[0])\n",
    "\n",
    "        # Considering only top k nodes\n",
    "        # liked_movie_nodes = liked_movie_nodes[:k]\n",
    "        # recommended_movie_nodes = recommended_movie_nodes[:k]\n",
    "        \n",
    "        ##### 4. Compute and store spearman rank correlation (and p value) between R and L.\n",
    "        # Null hypothesis is that the correlation is not positive, alternative hypothesis is that correlation is positive.\n",
    "        # Because some people have rated few movies, we use permutation test like in 'Examples' at https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.spearmanr.html\n",
    "        \n",
    "        ref = stats.permutation_test((x,), statistic, alternative='greater', permutation_type='pairings')\n",
    "        \n",
    "        r, p = spearmanr(liked_movie_nodes, recommended_movie_nodes, alternative='greater')\n",
    "        correlations.append(r)\n",
    "        p_values.append(p)\n",
    "        \n",
    "    \n",
    "    _, corrected_p_values, _, _ = multipletests(p_values, method='fdr_bh')  # Using Benjamini/Hochberg FDR correction (because we test many pre-detemined hypotheses) \n",
    "\n",
    "    # if p>0.05, correlation is set to 0\n",
    "    for i, p_value in enumerate(corrected_p_values):\n",
    "        if p_value>0.05:\n",
    "            correlations[i] = 0\n",
    "\n",
    "    # Computing and printing result\n",
    "    mean_correlation = np.mean(correlations)\n",
    "    std_correlation = np.std(correlations)\n",
    "    non_significant_proportion = np.mean(correlations==0)\n",
    "    print(f\"Average correlation ± std: {mean_correlation}±{std_correlation}, non-significant: {non_significant_proportion}\")\n",
    " \n",
    "def statistic(x):  # explore all possible pairings by permuting `x`\n",
    "    rs = stats.spearmanr(x, y).statistic  # ignore pvalue\n",
    "    transformed = rs * np.sqrt(dof / ((rs+1.0)*(1.0-rs)))\n",
    "    return transformed\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "640f1c55-757f-464c-b8f7-10578f3fffcf",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Lengths don't match: 21 != 1682.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msimple_weights_movies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[7], line 64\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(movie_graph, k, G, seed, default_rating)\u001b[0m\n\u001b[0;32m     59\u001b[0m     random\u001b[38;5;241m.\u001b[39mshuffle(missing_nodes)  \u001b[38;5;66;03m# randomizing order of non-recommended nodes\u001b[39;00m\n\u001b[0;32m     60\u001b[0m     recommended_movie_nodes\u001b[38;5;241m.\u001b[39mextend(missing_nodes)\n\u001b[1;32m---> 64\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(liked_movie_nodes) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(recommended_movie_nodes), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLengths don\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt match: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(liked_movie_nodes)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m != \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(recommended_movie_nodes)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mset\u001b[39m(liked_movie_nodes) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mset\u001b[39m(recommended_movie_nodes), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNode sets don\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt match.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# ##### 3. Sort R and L by node #####\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# liked_movie_nodes = sorted(liked_movie_nodes, key=lambda x:x[0])\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# recommended_movie_nodes = sorted(recommended_movie_nodes, key=lambda x:x[0])\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     75\u001b[0m \n\u001b[0;32m     76\u001b[0m \u001b[38;5;66;03m##### 4. Compute and store spearman rank correlation (and p value) between R and L.\u001b[39;00m\n",
      "\u001b[1;31mAssertionError\u001b[0m: Lengths don't match: 21 != 1682."
     ]
    }
   ],
   "source": [
    "# evaluate(simple_weights_movies, k=3, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "332df191-64a2-417d-b06c-6012cee1e2f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9500000000000001, 4.381261982543088e-05)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r, p = spearmanr([1,2,3,4,5,6,7,8,9],[2,3,1,4,5,6,7,8,9], alternative='greater')\n",
    "r, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b644dd2f-fd12-4363-84ba-34a92a4b2141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average correlation ± std: 0.200 ± 0.183, 33% non-significant.\n"
     ]
    }
   ],
   "source": [
    "correlations = [0, 0.1, 0.5, 0.3, 0.3, 0.0]\n",
    "\n",
    "mean_correlation = np.mean(correlations)\n",
    "std_correlation = np.std(correlations)\n",
    "non_significant_proportion = np.mean(np.array(correlations)==0)\n",
    "print(f\"Average correlation ± std: {mean_correlation:.3f} ± {std_correlation:.3f}, {non_significant_proportion:.0%} non-significant.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
